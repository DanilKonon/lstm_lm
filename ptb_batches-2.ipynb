{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXkg3T-m4JBa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSW7kB-d3LPA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33.2M  100 33.2M    0     0  1581k      0  0:00:21  0:00:21 --:--:-- 2503k    0     0   604k      0  0:00:56  0:00:04  0:00:52  604k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArMUuXsE4hsZ"
   },
   "outputs": [],
   "source": [
    "# !tar xvf simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'simple-examples/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZLnaTlL4JBi"
   },
   "outputs": [],
   "source": [
    "test_ptb = Path.cwd() / data_path / 'ptb.test.txt'\n",
    "train_ptb = Path.cwd() / data_path / 'ptb.train.txt'\n",
    "valid_ptb = Path.cwd() / data_path / 'ptb.valid.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4_MZVG-H4JBo",
    "outputId": "f6d6841e-4c49-4b42-9072-9c4904a98a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ptb.exists(), train_ptb.exists(), valid_ptb.exists() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvm-rT084JBy"
   },
   "outputs": [],
   "source": [
    "def read_ptb_file(ptb_file: Path):\n",
    "    ptb_dict = defaultdict(int)\n",
    "    one_line = []\n",
    "    with ptb_file.open(mode='r') as f:\n",
    "        for ind, sent in enumerate(f):\n",
    "            sent_words = sent.strip().split()\n",
    "            sent_words += ['<eos>']\n",
    "            for word in sent_words:\n",
    "                ptb_dict[word] += 1\n",
    "            one_line += sent_words\n",
    "    print(ind)\n",
    "    return ptb_dict, one_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BLPcWfc-4JB3",
    "outputId": "4d4dbbbf-00ba-4a9b-e318-253ee94d9b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3760\n",
      "42067\n",
      "3369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82430, 929589, 73760)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict, test_ol = read_ptb_file(test_ptb)\n",
    "train_dict, train_ol = read_ptb_file(train_ptb)\n",
    "valid_dict, valid_ol = read_ptb_file(valid_ptb)\n",
    "len(test_ol), len(train_ol), len(valid_ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "60J-85FQ4JCD",
    "outputId": "530159d5-3367-4ed4-9c24-d19a10c56875"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_dict.keys()).issuperset(set(valid_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2ZAJd7D4JCI"
   },
   "outputs": [],
   "source": [
    "word_to_ind = {k: ind for ind, (k, v) in enumerate(train_dict.items())}\n",
    "ind_to_word = {v: k for k, v in word_to_ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tf8DmAb84JCM"
   },
   "outputs": [],
   "source": [
    "num_layers = 2 \n",
    "emb_size = 650 \n",
    "batch_size = 20 \n",
    "num_steps = 35 \n",
    "vocab_size = len(train_dict)\n",
    "hidden_size = 650\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUSJIax64JCQ"
   },
   "outputs": [],
   "source": [
    "def indecise(one_line: list, word_to_ind: dict) -> list:\n",
    "    return [word_to_ind[word] for word in one_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K80jq2PH4JCV"
   },
   "outputs": [],
   "source": [
    "def batch_to_text(batch, ind_to_word):\n",
    "    vect_func = np.vectorize(lambda x: ind_to_word[x])\n",
    "    return vect_func(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxEHPFK74JCd"
   },
   "outputs": [],
   "source": [
    "def generate_batches(ol, word_to_ind, batch_size=5, num_steps=3):\n",
    "    ol = ol[0:(len(ol) // (batch_size * num_steps)) * batch_size * num_steps]\n",
    "    ind_ol = np.array(indecise(ol, word_to_ind))\n",
    "    ind_ol = ind_ol.reshape([batch_size, -1])\n",
    "    num_batches = ind_ol.shape[1] // num_steps\n",
    "    for i in range(num_batches):\n",
    "        yield ind_ol[:, i * num_steps: (i+1) * num_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-Q4PhcF4JCg"
   },
   "outputs": [],
   "source": [
    "# gen_batches_X = generate_batches(ol=train_ol, word_to_ind=word_to_ind, batch_size=batch_size, num_steps=num_steps)\n",
    "# gen_batches_Y = generate_batches(ol=train_ol[1:], word_to_ind=word_to_ind, batch_size=batch_size, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8YCLX9i4JCj"
   },
   "outputs": [],
   "source": [
    "# x0 = next(gen_batches_X)\n",
    "# y0 = next(gen_batches_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBPGxJqh58PP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7StrUKp4JCl"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LJhHAqC4JCo"
   },
   "outputs": [],
   "source": [
    "ph_input_seq = tf.placeholder(dtype=tf.int32, shape=(None, None), name='input_sequence') # bs, seq_len\n",
    "ph_target_seq = tf.placeholder(dtype=tf.int32, shape=(None, None), name='target_sequence') # bs, seq_len\n",
    "ph_lr = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "ph_keep_prob = tf.placeholder(dtype=tf.float32, name='keep_probability')\n",
    "ph_batch_size = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "ph_num_steps = tf.placeholder(tf.int32, [], name='num_steps_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FBdYdFt4JCr"
   },
   "outputs": [],
   "source": [
    "word_embeddings = tf.get_variable(name='word_embs', \n",
    "                                  shape=[vocab_size, emb_size], \n",
    "                                  initializer=tf.random_uniform_initializer(minval=-0.05, maxval=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCHwQ1Ut4JCs"
   },
   "outputs": [],
   "source": [
    "batch_mat = tf.nn.embedding_lookup(word_embeddings, ph_input_seq, name='word_emb_lookup')  # bs, seq_len, emb_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-gP7prjCXYx"
   },
   "outputs": [],
   "source": [
    "l_cell = tf.nn.rnn_cell.LSTMCell(num_units=hidden_size)\n",
    "d_cell = tf.nn.rnn_cell.DropoutWrapper(cell=l_cell, input_keep_prob=ph_keep_prob)\n",
    "lstm_layers = [d_cell for _ in range(2)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_layers)\n",
    "initial_state_multi = multi_cell.zero_state(ph_batch_size, dtype=tf.float32)\n",
    "outputs, state = tf.nn.dynamic_rnn(\n",
    "                              cell=multi_cell,\n",
    "                              inputs=batch_mat,\n",
    "                              dtype=tf.float32,\n",
    "                              initial_state=initial_state_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1Lwfn9k4JC1"
   },
   "outputs": [],
   "source": [
    "logits = tf.contrib.layers.fully_connected(outputs,  # batch_size, num_steps, vocab_size\n",
    "                                           num_outputs=vocab_size,\n",
    "                                           activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMMtZKdT4JC3"
   },
   "outputs": [],
   "source": [
    "probabs = tf.nn.softmax(logits) # batch_size, num_steps, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4_57WTS4JC5"
   },
   "outputs": [],
   "source": [
    "seq_mask = tf.ones(shape=[ph_batch_size, ph_num_steps], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0xR6b8O4JC6"
   },
   "outputs": [],
   "source": [
    "losses = tf.contrib.seq2seq.sequence_loss(logits,\n",
    "                                          ph_target_seq,\n",
    "                                          weights=seq_mask,\n",
    "                                          average_across_timesteps=True,\n",
    "                                          average_across_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4HkNpBC6-8v"
   },
   "outputs": [],
   "source": [
    "tvars= tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(losses, tvars),\n",
    "                                  max_grad_norm)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=ph_lr, )\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ivdzn7F37EEG",
    "outputId": "e54672b9-197e-4608-9719-4f957ecee8a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'word_embs:0' shape=(10000, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(400, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'fully_connected/weights:0' shape=(200, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'fully_connected/biases:0' shape=(10000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2MLbGNF4JC-"
   },
   "outputs": [],
   "source": [
    "# traininig_op = optimizer.minimize(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZl4fy0u4JDB"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bex0jhHO4JDE"
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJpQffk64JDH"
   },
   "outputs": [],
   "source": [
    "summary_loss = tf.summary.scalar(name='scalar_loss', tensor=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Azw6S8aC4JDK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-QHuW194JDM"
   },
   "outputs": [],
   "source": [
    "num_batches = len(train_ol) // (batch_size) // (num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4snZuyry4JDO"
   },
   "outputs": [],
   "source": [
    "def time_str():\n",
    "    return datetime.now().replace(microsecond=0).isoformat().replace(':', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2027
    },
    "colab_type": "code",
    "id": "S1tbBg1Q4JDQ",
    "outputId": "20d65754-b98d-4781-f993-f17157b1597d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.476135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-4314b4b04170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m                         loss, last_state = sess.run(\n\u001b[1;32m     62\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                             feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     64\u001b[0m                         \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0mtot_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m             raise TypeError('The value of a feed cannot be a tf.Tensor object. '\n\u001b[1;32m   1087\u001b[0m                             \u001b[0;34m'Acceptable feed values include Python scalars, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 39\n",
    "model_name = 'lm_ptb'\n",
    "step = 0\n",
    "lr = 1.0\n",
    "total_dev_losses = []\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter(model_name + '/summaries%s' % time_str(), sess.graph)\n",
    "    for i in range(n_epochs):\n",
    "        gen_batches_X = generate_batches(ol=train_ol, word_to_ind=word_to_ind, batch_size=batch_size, num_steps=num_steps)\n",
    "        gen_batches_Y = generate_batches(ol=train_ol[1:], word_to_ind=word_to_ind, batch_size=batch_size, num_steps=num_steps)\n",
    "        if i > 5:\n",
    "            lr /= 1.2\n",
    "        with tqdm(total=num_batches) as p:\n",
    "            last_state = None\n",
    "            for x, y in zip(gen_batches_X, gen_batches_Y):\n",
    "                feed_dict = {\n",
    "                        ph_input_seq: x, \n",
    "                        ph_target_seq: y,\n",
    "                        ph_lr: lr,\n",
    "                        ph_batch_size: batch_size,\n",
    "                        ph_num_steps: num_steps,\n",
    "                        ph_keep_prob: 0.5\n",
    "                    }\n",
    "                if last_state is not None:\n",
    "                    feed_dict[initial_state_multi] = last_state\n",
    "                        \n",
    "                    \n",
    "                _, last_state = sess.run(\n",
    "                    [train_op, state],\n",
    "                    feed_dict=feed_dict)\n",
    "\n",
    "                if step % 100 == 0:\n",
    "                    perplex = losses.eval(\n",
    "                        feed_dict=feed_dict\n",
    "                    )\n",
    "                    print(perplex)\n",
    "                    summ = sess.run(summary_loss, \n",
    "                             feed_dict=feed_dict)\n",
    "                    gen_batches_X = generate_batches(ol=valid_ol, \n",
    "                                                     word_to_ind=word_to_ind, \n",
    "                                                     batch_size=1, \n",
    "                                                     num_steps=1)\n",
    "                    gen_batches_Y = generate_batches(ol=valid_ol[1:], \n",
    "                                                     word_to_ind=word_to_ind, \n",
    "                                                     batch_size=1, \n",
    "                                                     num_steps=1)\n",
    "                    last_state = None\n",
    "                    k, tot_loss = 0, 0\n",
    "                    for x, y in zip(gen_batches_X, gen_batches_Y):\n",
    "                        feed_dict = {\n",
    "                            ph_input_seq: x, \n",
    "                            ph_target_seq: y,\n",
    "                            ph_batch_size: 1,\n",
    "                            ph_num_steps: 1,\n",
    "                            ph_keep_prob: 1\n",
    "                        }\n",
    "                        if last_state is not None:\n",
    "                            feed_dict[initial_state_multi] = last_state\n",
    "                        \n",
    "                    \n",
    "                        loss, last_state = sess.run(\n",
    "                            [losses, state],\n",
    "                            feed_dict=feed_dict)\n",
    "                        k += 1\n",
    "                        tot_loss += loss\n",
    "                    total_dev_losses.append(tot_loss / k)\n",
    "                    print(tot_loss / k)\n",
    "                        \n",
    "                        \n",
    "        if (i % 1 == 0):\n",
    "            print('Epoch ', i)\n",
    "            saver.save(sess,\n",
    "                       model_name + '/model_nt/model',\n",
    "                       global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o8xl2ri1AeQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5seqXZq4JDV"
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mu2BBvAoqkF"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-gWQR7TcnL1f",
    "outputId": "0cb6ef1e-7d6b-4e1b-840a-42e5686d4140"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'word_embs:0' shape=(10000, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(400, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(400, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'fully_connected/weights:0' shape=(200, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'fully_connected/biases:0' shape=(10000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dNa4AwybmcFC",
    "outputId": "d6843b4e-d20e-4b8d-d1df-c3f58c23eb5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lm_ptb/model_nt/model-29\n"
     ]
    }
   ],
   "source": [
    "new_saver = tf.train.import_meta_graph('./lm_ptb/model_nt/model-28.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint('./lm_ptb/model_nt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzNys0UH57Qc"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Fk60fbwo3jw"
   },
   "outputs": [],
   "source": [
    "gen_batches_X = generate_batches(ol=train_ol, word_to_ind=word_to_ind, batch_size=batch_size, num_steps=num_steps)\n",
    "gen_batches_Y = generate_batches(ol=train_ol[1:], word_to_ind=word_to_ind, batch_size=batch_size, num_steps=num_steps)\n",
    "x = next(gen_batches_X)\n",
    "y = next(gen_batches_Y)\n",
    "feed_dict = {\n",
    "    ph_input_seq: x, \n",
    "    ph_target_seq: y,\n",
    "    ph_lr: lr,\n",
    "    ph_batch_size: batch_size,\n",
    "    ph_num_steps: num_steps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=[ph_num_steps] * ph_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "HNn-jzhqpM3v",
    "outputId": "69355154-1f11-4ee1-8198-b14244671806"
   },
   "outputs": [],
   "source": [
    "b, n = sess.run([ph_batch_size, tf.shape(ph_input_seq)], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S22DPDnP6BzI",
    "outputId": "749f4f73-1015-4bf6-a4e9-6ae263d2515d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 35], dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "gB_cSZ4EqG-O",
    "outputId": "7f1599b9-2be4-41d4-dd18-eb831a787fce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  25],\n",
       "       [  26],\n",
       "       [  28],\n",
       "       ...,\n",
       "       [9954],\n",
       "       [9956],\n",
       "       [9968]])"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(prob[0, 1, :] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "DEVt_5qh4JDX",
    "outputId": "98299c41-d93b-4b39-cc28-55cc66121fd9"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-79-e43d833dd306>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    0sess.run(tf.global_variables_initializer())\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "0sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "DeL5C7qxpltE",
    "outputId": "9f0a64b7-7d4a-44cc-cbde-331641c4b51b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.7464739e+01, -3.6920895e+01, -3.6771332e+01, ...,\n",
       "         2.6273001e+01, -3.7348797e+01,  3.6746384e+01],\n",
       "       [ 6.3345112e+01, -9.7019281e+00, -5.1374656e-01, ...,\n",
       "        -1.0484942e+01,  1.3455794e+00,  6.3885632e+01],\n",
       "       [ 3.1979662e+01, -3.2417019e+01,  2.2178928e+01, ...,\n",
       "        -3.2884804e+01,  2.2129156e+01, -2.6629168e+01],\n",
       "       ...,\n",
       "       [-3.1723948e+01, -3.1731722e+01, -3.1821632e+01, ...,\n",
       "        -3.1739698e+01, -3.1674166e+01, -3.1669527e+01],\n",
       "       [ 3.0517769e+01,  3.0611116e+01,  3.0411850e+01, ...,\n",
       "         3.0528505e+01, -3.0427708e+01, -3.0400440e+01],\n",
       "       [ 7.7703960e-02, -5.8487877e-03,  3.9323784e-02, ...,\n",
       "         5.2389242e-02, -7.4387550e-02,  1.6977310e-02]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ODNq16F4JDZ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c2ca3d0141fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mph_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mph_input_seq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph_target_seq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x0' is not defined"
     ]
    }
   ],
   "source": [
    "stat = sess.run(ph_num_steps, feed_dict={ph_input_seq: x0, ph_target_seq: y0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4z_80FIP4JDc",
    "outputId": "ffe3baf5-86f1-4feb-9f0c-965ae5c116e3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-70e4fecf3f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stat' is not defined"
     ]
    }
   ],
   "source": [
    "stat[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "Dnd3kFSN4JDf",
    "outputId": "993f3e97-1b05-4ef9-82d6-bf1e31bcfc59"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 0; input has only 0 dims for 'strided_slice' (op: 'StridedSlice') with input shapes: [], [1], [1], [1] and with computed input tensors: input[3] = <1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-60736a91ecab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    818\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   9354\u001b[0m                         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9355\u001b[0m                         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9356\u001b[0;31m                         shrink_axis_mask=shrink_axis_mask, name=name)\n\u001b[0m\u001b[1;32m   9357\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9358\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index out of range using input dim 0; input has only 0 dims for 'strided_slice' (op: 'StridedSlice') with input shapes: [], [1], [1], [1] and with computed input tensors: input[3] = <1>."
     ]
    }
   ],
   "source": [
    "losses[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxN0sShZ4JDi"
   },
   "outputs": [],
   "source": [
    "sess.run(multi_cell.initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9_pQJd14JDj"
   },
   "outputs": [],
   "source": [
    "losses[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87Zn-z2D4JDm"
   },
   "outputs": [],
   "source": [
    "np.array_equal(out[:, 2, :], stat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QamYJiZg4JDp"
   },
   "outputs": [],
   "source": [
    "stat[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UyB3EGu4JDr"
   },
   "outputs": [],
   "source": [
    "stat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmF7YbB64JDt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kykKL78E4JDu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEbmq2GA4JDw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymGp2PvB4JDx"
   },
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydbuT8xa4JDy"
   },
   "outputs": [],
   "source": [
    "X_0 = tf.placeholder(dtype=tf.float32, shape=[None, n_inputs])\n",
    "X_1 = tf.placeholder(dtype=tf.float32, shape=[None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdkmA0tq4JD0"
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAEmo5-r4JD1"
   },
   "outputs": [],
   "source": [
    "output, states = tf.contrib.rnn.static_rnn(basic_cell, [X_0, X_1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqnbXnDk4JD3"
   },
   "outputs": [],
   "source": [
    "Y_0, Y_1 = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJDbobQ74JD4"
   },
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) \n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUnSF51z4JD5"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out, stat = sess.run([output, states], feed_dict={X_0: X0_batch, X_1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DA9lC9wk4JD7"
   },
   "outputs": [],
   "source": [
    "out[0].shape, np.array_equal(out[1], stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmxjzvWN4JD8"
   },
   "outputs": [],
   "source": [
    "X0_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1bTZbiI4JD_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ptb_batches.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
